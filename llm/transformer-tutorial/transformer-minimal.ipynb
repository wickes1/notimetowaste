{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For AMD RDNA 2 support\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"HSA_OVERRIDE_GFX_VERSION\"] = \"10.3.0\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this script to check if ROCm is installed and working properly\n",
    "\n",
    "import os\n",
    "import torch, grp, pwd, os, subprocess\n",
    "\n",
    "devices = []\n",
    "try:\n",
    "    print(\"\\n\\nChecking ROCM support...\")\n",
    "    result = subprocess.run([\"rocminfo\"], stdout=subprocess.PIPE)\n",
    "    cmd_str = result.stdout.decode(\"utf-8\")\n",
    "    cmd_split = cmd_str.split(\"Agent \")\n",
    "    for part in cmd_split:\n",
    "        item_single = part[0:1]\n",
    "        item_double = part[0:2]\n",
    "        if item_single.isnumeric() or item_double.isnumeric():\n",
    "            new_split = cmd_str.split(\"Agent \" + item_double)\n",
    "            device = (\n",
    "                new_split[1]\n",
    "                .split(\"Marketing Name:\")[0]\n",
    "                .replace(\"  Name:                    \", \"\")\n",
    "                .replace(\"\\n\", \"\")\n",
    "                .replace(\"                  \", \"\")\n",
    "                .split(\"Uuid:\")[0]\n",
    "                .split(\"*******\")[1]\n",
    "            )\n",
    "            devices.append(device)\n",
    "    if len(devices) > 0:\n",
    "        print(\"GOOD: ROCM devices found: \", len(devices))\n",
    "    else:\n",
    "        print(\"BAD: No ROCM devices found.\")\n",
    "\n",
    "    print(\"Checking PyTorch...\")\n",
    "    x = torch.rand(5, 3)\n",
    "    has_torch = False\n",
    "    len_x = len(x)\n",
    "    if len_x == 5:\n",
    "        has_torch = True\n",
    "        for i in x:\n",
    "            if len(i) == 3:\n",
    "                has_torch = True\n",
    "            else:\n",
    "                has_torch = False\n",
    "    if has_torch:\n",
    "        print(\"GOOD: PyTorch is working fine.\")\n",
    "    else:\n",
    "        print(\"BAD: PyTorch is NOT working.\")\n",
    "\n",
    "    print(\"Checking user groups...\")\n",
    "    user = os.getlogin()\n",
    "    groups = [g.gr_name for g in grp.getgrall() if user in g.gr_mem]\n",
    "    gid = pwd.getpwnam(user).pw_gid\n",
    "    groups.append(grp.getgrgid(gid).gr_name)\n",
    "    if \"render\" in groups and \"video\" in groups:\n",
    "        print(\"GOOD: The user\", user, \"is in RENDER and VIDEO groups.\")\n",
    "    else:\n",
    "        print(\n",
    "            \"BAD: The user\",\n",
    "            user,\n",
    "            \"is NOT in RENDER and VIDEO groups. This is necessary in order to PyTorch use HIP resources\",\n",
    "        )\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"GOOD: PyTorch ROCM support found.\")\n",
    "        t = torch.tensor([5, 5, 5], dtype=torch.int64, device=\"cuda\")\n",
    "        print(\"Testing PyTorch ROCM support...\")\n",
    "        if str(t) == \"tensor([5, 5, 5], device='cuda:0')\":\n",
    "            print(\"Everything fine! You can run PyTorch code inside of: \")\n",
    "            for device in devices:\n",
    "                print(\"---> \", device)\n",
    "    else:\n",
    "        print(\"BAD: PyTorch ROCM support NOT found.\")\n",
    "except:\n",
    "    print(\n",
    "        \"Cannot find rocminfo command information. Unable to determine if AMDGPU drivers with ROCM support were installed.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text Generation\n",
    "\n",
    "from transformers import GPT2Tokenizer, GPT2Model\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "model = GPT2Model.from_pretrained(\"gpt2\")\n",
    "text = \"Replace me by any text you'd like.\"\n",
    "encoded_input = tokenizer(text, return_tensors=\"pt\")\n",
    "output = model(**encoded_input)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding\n",
    "\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "# list of sentences\n",
    "sentences = [\n",
    "    \"sentence_0\",\n",
    "    \"sentence_1\",\n",
    "]\n",
    "\n",
    "# init model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"maidalun1020/bce-embedding-base_v1\")\n",
    "model = AutoModel.from_pretrained(\"maidalun1020/bce-embedding-base_v1\")\n",
    "\n",
    "device = \"cuda\"  # if no GPU, set \"cpu\"\n",
    "model.to(device)\n",
    "\n",
    "# get inputs\n",
    "inputs = tokenizer(\n",
    "    sentences, padding=True, truncation=True, max_length=512, return_tensors=\"pt\"\n",
    ")\n",
    "inputs_on_device = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "# get embeddings\n",
    "outputs = model(**inputs_on_device, return_dict=True)\n",
    "embeddings = outputs.last_hidden_state[:, 0]  # cls pooler\n",
    "embeddings = embeddings / embeddings.norm(dim=1, keepdim=True)  # normalize\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reranking\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# your query and corresponding passages\n",
    "query = \"input_query\"\n",
    "passages = [\"passage_0\", \"passage_1\"]\n",
    "\n",
    "# construct sentence pairs\n",
    "sentence_pairs = [[query, passage] for passage in passages]\n",
    "\n",
    "# init model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"maidalun1020/bce-reranker-base_v1\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"maidalun1020/bce-reranker-base_v1\"\n",
    ")\n",
    "\n",
    "device = \"cuda\"  # if no GPU, set \"cpu\"\n",
    "model.to(device)\n",
    "\n",
    "# get inputs\n",
    "inputs = tokenizer(\n",
    "    sentence_pairs, padding=True, truncation=True, max_length=512, return_tensors=\"pt\"\n",
    ")\n",
    "inputs_on_device = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "# calculate scores\n",
    "scores = (\n",
    "    model(**inputs_on_device, return_dict=True)\n",
    "    .logits.view(\n",
    "        -1,\n",
    "    )\n",
    "    .float()\n",
    ")\n",
    "scores = torch.sigmoid(scores)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text Generation\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=\"microsoft/Phi-3-mini-4k-instruct\",\n",
    "    trust_remote_code=True,\n",
    "    device=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text Classification\n",
    "from transformers import pipeline\n",
    "\n",
    "\n",
    "pipe = pipeline(\"text-classification\", device=0)\n",
    "pipe([\"This restaurant is awesome\", \"This restaurant is awful\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatic Speech Recognition with Datasets\n",
    "\n",
    "import datasets\n",
    "from transformers import pipeline\n",
    "from transformers.pipelines.pt_utils import KeyDataset\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"automatic-speech-recognition\", model=\"facebook/wav2vec2-base-960h\", device=0\n",
    ")\n",
    "dataset = datasets.load_dataset(\"superb\", name=\"asr\", split=\"test\")\n",
    "\n",
    "# KeyDataset (only *pt*) will simply return the item in the dict returned by the dataset item\n",
    "# as we're not interested in the *target* part of the dataset. For sentence pair use KeyPairDataset\n",
    "for out in tqdm(pipe(KeyDataset(dataset, \"file\"))):\n",
    "    print(out)\n",
    "    # {\"text\": \"NUMBER TEN FRESH NELLY IS WAITING ON YOU GOOD NIGHT HUSBAND\"}\n",
    "    # {\"text\": ....}\n",
    "    # ...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarization\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "summarizer = pipeline(\"summarization\", device=0)\n",
    "summarizer(\"An apple a day, keeps the doctor away\", min_length=5, max_length=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Object Detection\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "detector = pipeline(task=\"object-detection\", device=0)\n",
    "preds = detector(\n",
    "    \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg\"\n",
    ")\n",
    "preds = [\n",
    "    {\"score\": round(pred[\"score\"], 4), \"label\": pred[\"label\"], \"box\": pred[\"box\"]}\n",
    "    for pred in preds\n",
    "]\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Audio Classification\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"audio-classification\", device=0)\n",
    "classifier(\"https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/1.flac\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
