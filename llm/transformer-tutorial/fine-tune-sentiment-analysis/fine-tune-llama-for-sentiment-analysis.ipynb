{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tune Llama 2 for sentiment analysis\n",
    "\n",
    "Download datasets from [Fine-tune Llama 2 for sentiment analysis](https://www.kaggle.com/code/lucamassaron/fine-tune-llama-2-for-sentiment-analysis/notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# for ROCm, 10.3.0 is gfx1030\n",
    "os.environ[\"HSA_OVERRIDE_GFX_VERSION\"] = \"10.3.0\"\n",
    "# for multiple GPUs ,e.g. you have GPU + iGPU/APU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "import bitsandbytes as bnb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import transformers\n",
    "from datasets import Dataset\n",
    "from peft import LoraConfig, PeftConfig\n",
    "from trl import SFTTrainer\n",
    "from trl import setup_chat_format\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    "    logging,\n",
    ")\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytorch version 2.3.1+rocm6.0\n",
      "bitsandbytes version 0.43.2.dev\n",
      "working on cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(f\"pytorch version {torch.__version__}\")\n",
    "print(f\"bitsandbytes version {bnb.__version__}\")\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"working on {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"./all-data.csv\"\n",
    "\n",
    "df = pd.read_csv(\n",
    "    filename, names=[\"sentiment\", \"text\"], encoding=\"utf-8\", encoding_errors=\"replace\"\n",
    ")\n",
    "\n",
    "X_train = list()\n",
    "X_test = list()\n",
    "for sentiment in [\"positive\", \"neutral\", \"negative\"]:\n",
    "    train, test = train_test_split(\n",
    "        df[df.sentiment == sentiment], train_size=300, test_size=300, random_state=42\n",
    "    )\n",
    "    X_train.append(train)\n",
    "    X_test.append(test)\n",
    "\n",
    "X_train = pd.concat(X_train).sample(frac=1, random_state=10)\n",
    "X_test = pd.concat(X_test)\n",
    "\n",
    "eval_idx = [\n",
    "    idx for idx in df.index if idx not in list(X_train.index) + list(X_test.index)\n",
    "]\n",
    "X_eval = df[df.index.isin(eval_idx)]\n",
    "X_eval = X_eval.groupby(\"sentiment\", group_keys=False).apply(\n",
    "    lambda x: x.sample(n=50, random_state=10, replace=True)\n",
    ")\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "\n",
    "\n",
    "def generate_prompt(data_point):\n",
    "    return f\"\"\"\n",
    "            Analyze the sentiment of the news headline enclosed in square brackets,\n",
    "            determine if it is positive, neutral, or negative, and return the answer as\n",
    "            the corresponding sentiment label \"positive\" or \"neutral\" or \"negative\".\n",
    "\n",
    "            [{data_point[\"text\"]}] = {data_point[\"sentiment\"]}\n",
    "            \"\"\".strip()\n",
    "\n",
    "\n",
    "def generate_test_prompt(data_point):\n",
    "    return f\"\"\"\n",
    "            Analyze the sentiment of the news headline enclosed in square brackets,\n",
    "            determine if it is positive, neutral, or negative, and return the answer as\n",
    "            the corresponding sentiment label \"positive\" or \"neutral\" or \"negative\".\n",
    "\n",
    "            [{data_point[\"text\"]}] = \"\"\".strip()\n",
    "\n",
    "\n",
    "X_train = pd.DataFrame(X_train.apply(generate_prompt, axis=1), columns=[\"text\"])\n",
    "X_eval = pd.DataFrame(data=X_eval.apply(generate_prompt, axis=1), columns=[\"text\"])\n",
    "\n",
    "y_true = X_test.sentiment\n",
    "X_test = pd.DataFrame(X_test.apply(generate_test_prompt, axis=1), columns=[\"text\"])\n",
    "\n",
    "train_data = Dataset.from_pandas(X_train)\n",
    "eval_data = Dataset.from_pandas(X_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(y_true, y_pred):\n",
    "    labels = [\"positive\", \"neutral\", \"negative\"]\n",
    "    mapping = {\"positive\": 2, \"neutral\": 1, \"none\": 1, \"negative\": 0}\n",
    "\n",
    "    def map_func(x):\n",
    "        return mapping.get(x, 1)\n",
    "\n",
    "    y_true = np.vectorize(map_func)(y_true)\n",
    "    y_pred = np.vectorize(map_func)(y_pred)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_true=y_true, y_pred=y_pred)\n",
    "    print(f\"Accuracy: {accuracy:.3f}\")\n",
    "\n",
    "    # Generate accuracy report\n",
    "    unique_labels = set(y_true)  # Get unique labels\n",
    "\n",
    "    for label in unique_labels:\n",
    "        label_indices = [i for i in range(len(y_true)) if y_true[i] == label]\n",
    "        label_y_true = [y_true[i] for i in label_indices]\n",
    "        label_y_pred = [y_pred[i] for i in label_indices]\n",
    "        accuracy = accuracy_score(label_y_true, label_y_pred)\n",
    "        print(f\"Accuracy for label {label}: {accuracy:.3f}\")\n",
    "\n",
    "    # Generate classification report\n",
    "    class_report = classification_report(y_true=y_true, y_pred=y_pred)\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(class_report)\n",
    "\n",
    "    # Generate confusion matrix\n",
    "    conf_matrix = confusion_matrix(y_true=y_true, y_pred=y_pred, labels=[0, 1, 2])\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06fe5d493a904aa997ebc7db64976f83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"microsoft/Phi-3-mini-4k-instruct\"\n",
    "\n",
    "compute_dtype = getattr(torch, \"float16\")\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=compute_dtype,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=device,\n",
    "    torch_dtype=compute_dtype,\n",
    "    quantization_config=bnb_config,\n",
    ")\n",
    "\n",
    "model.config.use_cache = False\n",
    "model.config.pretraining_tp = 1\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_name,\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\"\n",
    "\n",
    "model, tokenizer = setup_chat_format(model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(test, model, tokenizer):\n",
    "    y_pred = []\n",
    "    for i in tqdm(range(len(X_test))):\n",
    "        prompt = X_test.iloc[i][\"text\"]\n",
    "        pipe = pipeline(\n",
    "            task=\"text-generation\",\n",
    "            model=model,\n",
    "            tokenizer=tokenizer,\n",
    "            max_new_tokens=1,\n",
    "            temperature=0.0,\n",
    "        )\n",
    "        result = pipe(prompt)\n",
    "        answer = result[0][\"generated_text\"].split(\"=\")[-1]\n",
    "        if \"positive\" in answer:\n",
    "            y_pred.append(\"positive\")\n",
    "        elif \"negative\" in answer:\n",
    "            y_pred.append(\"negative\")\n",
    "        elif \"neutral\" in answer:\n",
    "            y_pred.append(\"neutral\")\n",
    "        else:\n",
    "            y_pred.append(\"none\")\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/900 [00:00<?, ?it/s]You are not running the flash-attention implementation, expect numerical differences.\n",
      "100%|██████████| 900/900 [01:40<00:00,  8.95it/s]\n"
     ]
    }
   ],
   "source": [
    "y_pred = predict(test, model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.669\n",
      "Accuracy for label 0: 0.970\n",
      "Accuracy for label 1: 0.620\n",
      "Accuracy for label 2: 0.417\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.97      0.79       300\n",
      "           1       0.60      0.62      0.61       300\n",
      "           2       0.81      0.42      0.55       300\n",
      "\n",
      "    accuracy                           0.67       900\n",
      "   macro avg       0.69      0.67      0.65       900\n",
      "weighted avg       0.69      0.67      0.65       900\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[291   8   1]\n",
      " [ 86 186  28]\n",
      " [ 60 115 125]]\n"
     ]
    }
   ],
   "source": [
    "evaluate(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06367e8ab72f4cb9bf011636155db243",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/900 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e2bfd03f2834270a62677d2b3e5818a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/150 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output_dir = \"trained_weights\"\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    r=64,\n",
    "    bias=\"none\",\n",
    "    target_modules=\"all-linear\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "training_arguments = TrainingArguments(\n",
    "    output_dir=output_dir,  # directory to save and repository id\n",
    "    num_train_epochs=3,  # number of training epochs\n",
    "    per_device_train_batch_size=1,  # batch size per device during training\n",
    "    gradient_accumulation_steps=8,  # number of steps before performing a backward/update pass\n",
    "    gradient_checkpointing=True,  # use gradient checkpointing to save memory\n",
    "    optim=\"paged_adamw_32bit\",\n",
    "    save_steps=0,\n",
    "    logging_steps=25,  # log every 10 steps\n",
    "    learning_rate=2e-4,  # learning rate, based on QLoRA paper\n",
    "    weight_decay=0.001,\n",
    "    fp16=True,\n",
    "    bf16=False,\n",
    "    max_grad_norm=0.3,  # max gradient norm based on QLoRA paper\n",
    "    max_steps=-1,\n",
    "    warmup_ratio=0.03,  # warmup ratio based on QLoRA paper\n",
    "    group_by_length=True,\n",
    "    lr_scheduler_type=\"cosine\",  # use cosine learning rate scheduler\n",
    "    report_to=\"tensorboard\",  # report metrics to tensorboard\n",
    "    evaluation_strategy=\"epoch\",  # save checkpoint every epoch\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=training_arguments,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=eval_data,\n",
    "    peft_config=peft_config,\n",
    "    dataset_text_field=\"text\",\n",
    "    tokenizer=tokenizer,\n",
    "    max_seq_length=1024,\n",
    "    packing=False,\n",
    "    dataset_kwargs={\n",
    "        \"add_special_tokens\": False,\n",
    "        \"append_concat_token\": False,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbe47e3ab28e489ba9c3ddeff20ebe98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/336 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.5626, 'grad_norm': 0.14719325304031372, 'learning_rate': 0.0001990856842874641, 'epoch': 0.22}\n",
      "{'loss': 0.9383, 'grad_norm': 0.13051626086235046, 'learning_rate': 0.00019297764858882514, 'epoch': 0.44}\n",
      "{'loss': 0.8695, 'grad_norm': 0.1571911722421646, 'learning_rate': 0.00018146608991420534, 'epoch': 0.67}\n",
      "{'loss': 0.9152, 'grad_norm': 0.1308598816394806, 'learning_rate': 0.0001652200182109602, 'epoch': 0.89}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39e79aec2b6c4303a5ca1930c75d19ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7957496643066406, 'eval_runtime': 9.6754, 'eval_samples_per_second': 15.503, 'eval_steps_per_second': 1.964, 'epoch': 1.0}\n",
      "{'loss': 0.8328, 'grad_norm': 0.1403578668832779, 'learning_rate': 0.0001451835961144145, 'epoch': 1.11}\n",
      "{'loss': 0.7734, 'grad_norm': 0.20339500904083252, 'learning_rate': 0.00012252126764738844, 'epoch': 1.33}\n",
      "{'loss': 0.7638, 'grad_norm': 0.18621598184108734, 'learning_rate': 9.855008496617327e-05, 'epoch': 1.56}\n",
      "{'loss': 0.7756, 'grad_norm': 0.2258760631084442, 'learning_rate': 7.466316607649738e-05, 'epoch': 1.78}\n",
      "{'loss': 0.7611, 'grad_norm': 0.16866222023963928, 'learning_rate': 5.2248731878811365e-05, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66701cdd8cb84fc48843118499154deb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7744114398956299, 'eval_runtime': 10.0926, 'eval_samples_per_second': 14.862, 'eval_steps_per_second': 1.883, 'epoch': 2.0}\n",
      "{'loss': 0.7261, 'grad_norm': 0.1970079243183136, 'learning_rate': 3.2609427815531426e-05, 'epoch': 2.22}\n",
      "{'loss': 0.7273, 'grad_norm': 0.21473923325538635, 'learning_rate': 1.6886618852849724e-05, 'epoch': 2.44}\n",
      "{'loss': 0.6818, 'grad_norm': 0.21480531990528107, 'learning_rate': 5.994057497592031e-06, 'epoch': 2.67}\n",
      "{'loss': 0.6671, 'grad_norm': 0.22301256656646729, 'learning_rate': 5.647798228764156e-07, 'epoch': 2.89}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa7eb0e5c2854c0cb29c0cdb74ec8214",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7884143590927124, 'eval_runtime': 10.1034, 'eval_samples_per_second': 14.846, 'eval_steps_per_second': 1.881, 'epoch': 2.99}\n",
      "{'train_runtime': 2021.2358, 'train_samples_per_second': 1.336, 'train_steps_per_second': 0.166, 'train_loss': 0.8362029762495131, 'epoch': 2.99}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=336, training_loss=0.8362029762495131, metrics={'train_runtime': 2021.2358, 'train_samples_per_second': 1.336, 'train_steps_per_second': 0.166, 'total_flos': 5931624305147904.0, 'train_loss': 0.8362029762495131, 'epoch': 2.986666666666667})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('trained_weigths/tokenizer_config.json',\n",
       " 'trained_weigths/special_tokens_map.json',\n",
       " 'trained_weigths/tokenizer.json')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save trained model and tokenizer\n",
    "trainer.save_model()\n",
    "tokenizer.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "del [\n",
    "    model,\n",
    "    tokenizer,\n",
    "    peft_config,\n",
    "    trainer,\n",
    "    train_data,\n",
    "    eval_data,\n",
    "    bnb_config,\n",
    "    training_arguments,\n",
    "]\n",
    "del [df, X_train, X_eval]\n",
    "del [TrainingArguments, SFTTrainer, LoraConfig, BitsAndBytesConfig]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(100):\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "372d0bbf31254fa6a5dcf9cb63cd25b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./merged_model/tokenizer_config.json',\n",
       " './merged_model/special_tokens_map.json',\n",
       " './merged_model/tokenizer.json')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from peft import AutoPeftModelForCausalLM\n",
    "\n",
    "finetuned_model = \"./trained_weigths/\"\n",
    "compute_dtype = getattr(torch, \"float16\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "model = AutoPeftModelForCausalLM.from_pretrained(\n",
    "    finetuned_model,\n",
    "    torch_dtype=compute_dtype,\n",
    "    return_dict=False,\n",
    "    low_cpu_mem_usage=True,\n",
    "    device_map=device,\n",
    ")\n",
    "\n",
    "merged_model = model.merge_and_unload()\n",
    "merged_model.save_pretrained(\n",
    "    \"./merged_model\", safe_serialization=True, max_shard_size=\"2GB\"\n",
    ")\n",
    "tokenizer.save_pretrained(\"./merged_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 900/900 [01:29<00:00, 10.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.861\n",
      "Accuracy for label 0: 0.957\n",
      "Accuracy for label 1: 0.720\n",
      "Accuracy for label 2: 0.907\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.96      0.95       300\n",
      "           1       0.87      0.72      0.79       300\n",
      "           2       0.79      0.91      0.84       300\n",
      "\n",
      "    accuracy                           0.86       900\n",
      "   macro avg       0.87      0.86      0.86       900\n",
      "weighted avg       0.87      0.86      0.86       900\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[287   8   5]\n",
      " [ 15 216  69]\n",
      " [  5  23 272]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = predict(test, merged_model, tokenizer)\n",
    "evaluate(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs/runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = pd.DataFrame(\n",
    "    {\"text\": X_test[\"text\"], \"y_true\": y_true, \"y_pred\": y_pred},\n",
    ")\n",
    "evaluation.to_csv(\"test_predictions.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
